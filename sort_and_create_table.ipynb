{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from traitlets.traitlets import Set\n",
        "#Sort the k-mers alphabetically\n",
        "def sort(read1,read2,num_frequent_k_mers):\n",
        "    size=len(read1)+len(read2)\n",
        "     #key is read_ID+k-mer index\n",
        "    with_ID_read1={}\n",
        "    for key in read1:\n",
        "      k=str(1)+\" \"+str(key)\n",
        "      with_ID_read1[k]=read1[key]\n",
        "    with_ID_read2={}\n",
        "    for key in read2:\n",
        "      k=str(2)+\" \"+str(key)\n",
        "      with_ID_read2[k]=read2[key]\n",
        "    with_ID_read1.update(with_ID_read2)\n",
        "    #Sort the merged dictionary;key is the index in the unsorted dictionary\n",
        "    sorted_keys = sorted(with_ID_read1, key=with_ID_read1.get)\n",
        "    #sorted_merged_reads=sorted(with_ID_read1)\n",
        "    sorted_merged_reads={}\n",
        "    for w in sorted_keys:\n",
        "       sorted_merged_reads[w] = with_ID_read1[w]\n",
        "    #Eliminate the k_mers that occur too often\n",
        "    sorted_merged_reads=eliminate(sorted_merged_reads,num_frequent_k_mers)\n",
        "    table={}\n",
        "    unique_k_mer=sorted(set(list(sorted_merged_reads.values())))\n",
        "    #for each k_mer, find its occurences in both reads\n",
        "    for k_mer in unique_k_mer:\n",
        "      read_1_indices=[]\n",
        "      read_2_indices=[]\n",
        "      #Get a set of positions of the k_mers\n",
        "      value = {i for i in sorted_merged_reads if sorted_merged_reads[i]==k_mer}\n",
        "      \n",
        "      #for each position in the set\n",
        "      for key in value:\n",
        "          #split the key into read_ID and index\n",
        "          split_key=key.split(\" \")\n",
        "          #print(split_key)\n",
        "          if split_key[0]=='1':\n",
        "            read_1_indices.append(split_key[1])\n",
        "          else:\n",
        "            read_2_indices.append(split_key[1])\n",
        "      size=max(len(read_1_indices),len(read_2_indices))\n",
        "      values=np.zeros([2,size])\n",
        "      values[0,0:len(read_1_indices)]=read_1_indices\n",
        "      values[1,0:len(read_2_indices)]=read_2_indices\n",
        "      table[k_mer]=values\n",
        "    return table\n",
        "\n"
      ],
      "metadata": {
        "id": "MifjDlLwSxjK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Eliminate the k_mers that occur too often\n",
        "from collections import Counter\n",
        "def eliminate(merged_dict,number):\n",
        "  k_mers=list(merged_dict.values())  \n",
        "  #count the occurence of all k_mers\n",
        "  counts = Counter(k_mers)\n",
        "  #return the n most common k_mers\n",
        "  most_common=counts.most_common(number)\n",
        "  for i in range(number):\n",
        "      merged_dict = {key:val for key, val in merged_dict.items() if val != most_common[i][0]}\n",
        "  return merged_dict"
      ],
      "metadata": {
        "id": "aC1fsWuFB-dl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}